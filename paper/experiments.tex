\subsection{Experiments}
\label{sec:experiments}

\subsubsection{Data sets}

Let us describe experiments and their results. All of our algorithms search for an odd hole or an odd antihole and stop when find one, or a evidence of one. Therefore, their running times are greatest with perfect graphs on the input and we decided to use mainly\todo{run some smart nonperfect tests} perfect graphs for our performance benchmarks.

We ran tests on X classes of perfect graphs, see \Cref{fig:graphClasses} for some examples:
\begin{itemize}
  \item Random perfect graphs,
  \item Random bipartite graphs,
  \item Line graphs of random bipartite graphs,
  \item Lattice graphs (\cref{fig:lattice}),
  \item Rook graphs (\cref{fig:rook}),
  \item Knight graphs (\cref{fig:knight}),
  \item Hypercube graphs (\cref{fig:hypercube}),
  \item Split graphs (\cref{fig:split}).
\end{itemize}

In later paragraphs we describe each class one by one and benchmark our implementations on them.

\begin{figure}
  \input{tikzpictures/graphs.tex}
  \caption{Graph classes}
  \label{fig:graphClasses}
\end{figure}

\paragraph{Random perfect graphs}
Our first method of generating graphs is to set $|V|$ and for each pair of vertices $u, v$ let $uv$ be the edge with probability of $1/2$. Then we check if generated graph is perfect and continue as long as we don't get sufficient number of perfect graphs.

First, we note that this method of generating perfect graphs is very inefficient and we couldn't generate any graphs with $|V| \geq 20$. Second, those graphs favour the na\"ive algortihm, because there is very low probability of long chordless paths to appear (each chord has a $1/2$ chance to appear).

When looking at the results (\Cref{plot:perfLines}), while na\"ive algorithm's time is almost zero, we ser the CCLSV running time climbing with the growth of $|V|$, with only moderate improvement by GPU CCLSV. Slight GPU improvement is explained by anylysis of the components of the overall time (\Cref{plot:perfDet}). Testing all near cleaners takes up around half of total time, so we cannot speed up the overall time by much. These are also relatively small tests, so the latency from copying data to the GPU is significant.

\TODO{Better plot by a lot WIP}

\begin{figure}
  \begin{subfigure}{\textwidth}
    \centering
    \input{plots/perf.t.in.out.csv.lines.pgf}
    \caption{Random perfect graphs}
    \label{plot:perfLines}
  \end{subfigure}

  \begin{subfigure}{\textwidth}
    \centering
    \input{plots/perf.t.in.out.csv.detailed.pgf}
    \caption{Random perfect graphs}
    \label{plot:perfDet}
  \end{subfigure}
  \caption{Random perfect graphs}
\end{figure}

\paragraph{Random bipartite graphs}
\TODO{TODO}

\paragraph{Line graphs of random bipartite graphs}
\TODO{data with bigger N}
Next, we generated a random bipartite graphs (see paragraph above) and then calculated their line graphs. We repeated the process until we had sufficieng number of graphs for each $|V|$. On \cref{plot:perf2Lines} we can see GPU gives us much better improvement than in random graphs. This is due to the fact, that testing near cleaners takes over 80\% of the time for bigger graphs (\Cref{plot:perf2Det}).

\begin{figure}
  \begin{subfigure}{\textwidth}
    \centering
    \input{plots/perf2.t.in.out.csv.lines.pgf}
    \caption{Line graphs of random bipartite graphs}
    \label{plot:perf2Lines}
  \end{subfigure}

  \begin{subfigure}{\textwidth}
    \centering
    \input{plots/perf2.t.in.out.csv.detailed.pgf}
    \caption{Line graphs of random bipartite graphs}
    \label{plot:perf2Det}
  \end{subfigure}
  \caption{Line graphs of random bipartite graphs}
\end{figure}

\paragraph{Lattice graphs}

Next, we turn our attention to graphs generated on a grid, or a checker board (see later paragraphs). First, we take lattice graphs. In lattice graph, each vertex is connected to vertices that are above, below, to the left and to the right of it, if such vertices exist. See \cref{fig:lattice} for an example of $4 \times 4$ lattice.

Let us take a look at \cref{plot:gridLines}. It is a clear example of why polynomial algorithms can be useful, even the ones with time complexity as high as CCLSV. For $|V| = 48$ the running time for the CCLSV is 22.2s, for GPU CCLSV is 7.7s and for na\"ive is 1.5s. Na\"ive is almost 15x faster. But with growing $|V|$ its running time grows very fast, reaching 41s for $|V| = 60$ and 210s for $|V| = 66$. CCLSV growth is much gentler and for $|V| = 66$ it is 2.5x faster than na\"ive.

With growing $|V|$ also grows the speedup gained from utilizing GPU. For $|V| = 78$ the running time for the whole algorithm is almost 3x better.

\begin{figure}
  \begin{subfigure}{\textwidth}
    \centering
    \input{plots/grid6by5to11.t.in.out.csv.lines.pgf}
    \caption{Overall running times}
    \label{plot:gridLines}
  \end{subfigure}

  \begin{subfigure}{\textwidth}
    \centering
    \input{plots/grid6by5to11.t.in.out.csv.detailed.pgf}
    \caption{Percentage of time taken be each part}
    \label{plot:gridDet}
  \end{subfigure}
  \caption{Lattice graphs}
\end{figure}

\paragraph{Rook graphs}

If we imagine our grid to be a chessboard we can define a Rook graph to have an edge, when the rook from chess can move from one vertex to another in one move. See \cref{fig:rook} for an example of $4 \times 4$ Rook graph.

Rook graphs have many more chords than Lattice graphs, so the na\"ive's performance is much better here. What is more interesting, the overall performance of CCLSV is much worse (\cref{plot:rookLines}). Looking at \cref{fig:rookDet} we can see that the majority of CCLSV time is spent checking all near cleaners. This can be explained by the fact that rook graphs are much denser than lattice graphs and have many more 3-vertex paths (see \cref{alg:testNearCleaner}). This is confirmed by greater CCLSV GPU speedup of around 6x on graph with $|V| = 35$.

\begin{figure}
  \begin{subfigure}{\textwidth}
    \centering
    \input{plots/rookGraph5by4to7.t.in.out.csv.lines.pgf}
    \caption{Overall running times}
    \label{plot:rookLines}
  \end{subfigure}

  \begin{subfigure}{\textwidth}
    \centering
    \input{plots/rookGraph5by4to7.t.in.out.csv.detailed.pgf}
    \caption{Percentage of time taken be each part}
    \label{plot:rookDet}
  \end{subfigure}
  \caption{Rook graphs}
\end{figure}

\paragraph{Knight graph}

A knight graph is constructed in a similar way to rook graph, but by taking potential moves of a knight.

\TODO{add 800s result for naive}

\begin{figure}
  \begin{subfigure}{\textwidth}
    \centering
    \input{plots/knightGraph8by4to8.t.in.out.csv.lines.pgf}
    \caption{Overall running times}
    \label{plot:knightLines}
  \end{subfigure}

  \begin{subfigure}{\textwidth}
    \centering
    \input{plots/knightGraph8by4to8.t.in.out.csv.detailed.pgf}
    \caption{Percentage of time taken be each part}
    \label{plot:knightDet}
  \end{subfigure}
  \caption{Knight graphs}
\end{figure}

\paragraph{Hypercube graphs}

A hypercube is a generalization of a cube to a higher dimensional space. We use hypercubes that are not complete, to achieve higher granularity of data. In a hypercube of $n$ vertices there is an edge between vertices $u$ and $v$ if and only if binary representations of $u$ and $v$ differ by exactly one bit.

Hypercube graphs tell a similar story to lattice graphs and knight graphs. Na\"ive is very fast at first, but becomes unbearably slow for $|V|$ higher than 55. Unfortunately, CCLSV doesnt fare much better, although it grows slower. Again, the speedup of GPU CCLSV is noticeable, being around 4.8x for $|V| = 55$.

\begin{figure}
  \begin{subfigure}{\textwidth}
    \centering
    \input{plots/hypercubes20to55.t.in.out.csv.lines.pgf}
    \caption{Overall running times}
    \label{plot:hypercubeLines}
  \end{subfigure}

  \begin{subfigure}{\textwidth}
    \centering
    \input{plots/knightGraph8by4to8.t.in.out.csv.detailed.pgf}
    \caption{Percentage of time taken be each part}
    \label{plot:hypercubeDet}
  \end{subfigure}
  \caption{Hypercube graphs}
\end{figure}

\paragraph{Split graphs}

Split graphs we use are unions of cliques and independent sets of same size, with some edges between them. In generating them, each edge between a vertex from a clique and a vertex from an independent set has had $1/2$ chance to appear.

There are no long chordless paths here, so na\"ive fares great (\cref{plot:splitLines}). What is interesting, when looking at detailed times of GPU CCLSV, we can see that checking the existence of simple forbidden structures takes more than 30\% of the time. This opens a possibility of further GPU speedups, as previous tests indicated that checking simple forbidden structures is usually very quick on the CPU.

\begin{figure}
  \begin{subfigure}{\textwidth}
    \centering
    \input{plots/split20to50.t.in.out.csv.lines.pgf}
    \caption{Overall running times}
    \label{plot:splitLines}
  \end{subfigure}

  \begin{subfigure}{\textwidth}
    \centering
    \input{plots/split20to50.t.in.out.csv.detailed.pgf}
    \caption{Percentage of time taken be each part}
    \label{plot:splitDet}
  \end{subfigure}
  \caption{Split graphs}
\end{figure}

\pagebreak
\section{Coloring Berge Graphs}

\subsection{Ellipsoid method}

We used an open source CSDP \cite{csdpRepo, csdp1999} library, that implements predictor corrector variant of the semidefinite programming algorithm to calculate $\vartheta(G)$, given $G$ on the input. The CSDP library has been used in many recent publications across different fields, such as \cite{Ampountolas_2017, Adasme_2011}.

\TODO{setting $\epsilon = 1/2$ in csdp helped a lot -- how much?}

Calculating $\vartheta(G)$ is the most complicated part of the coloring algorithm. With that done by an external library, the rest of the program is a straightforward implementation of the algorithms in \cref{sec:coloringEllipsoid}. Our main goal of the implementation was to check if this method is still impractical, even on modern equipment. Let us proceed straight to experiments and results.

\subsubsection{Experiments and results}

\begin{figure}
  \begin{subfigure}{.5\textwidth}
    \centering
    \input{plots/color.perf.t.in.out.csv.lines.pgf}
    \caption{Overall running times}
  \end{subfigure}%
  \begin{subfigure}{.5\textwidth}
    \centering
    \input{plots/color.perf.t.in.out.csv.detailed.pgf}
    \caption{Percentage of time taken be each part}
  \end{subfigure}
  \caption{Random perfect graphs}
\end{figure}

\begin{figure}
  \TODO{TODO}
  % \begin{subfigure}{.5\textwidth}
  %   \centering
  %   \input{plots/color.perf2.t.in.out.csv.lines.pgf}
  %   \caption{Overall running times}
  %   \label{plot:colorPerfLines}
  % \end{subfigure}%
  % \begin{subfigure}{.5\textwidth}
  %   \centering
  %   \input{plots/color.perf2.t.in.out.csv.detailed.pgf}
  %   \caption{Percentage of time taken be each part}
  %   \label{plot:colorPerfDet}
  % \end{subfigure}
  \caption{Line graphs of random bipartite graphs}
\end{figure}

\begin{figure}
  \begin{subfigure}{.5\textwidth}
    \centering
    \input{plots/color.grid5by4to9.t.in.out.csv.lines.pgf}
    \caption{Overall running times}
  \end{subfigure}%
  \begin{subfigure}{.5\textwidth}
    \centering
    \input{plots/color.grid5by4to9.t.in.out.csv.detailed.pgf}
    \caption{Percentage of time taken be each part}
  \end{subfigure}
  \caption{Lattice graphs}
\end{figure}

\begin{figure}
  \begin{subfigure}{.5\textwidth}
    \centering
    \input{plots/color.rookGraph6by4to8.t.in.out.csv.lines.pgf}
    \caption{Overall running times}
  \end{subfigure}%
  \begin{subfigure}{.5\textwidth}
    \centering
    \input{plots/color.rookGraph6by4to8.t.in.out.csv.detailed.pgf}
    \caption{Percentage of time taken be each part}
    \label{plot:colorRookDet}
  \end{subfigure}
  \caption{Rook graphs}
\end{figure}

\begin{figure}
  \begin{subfigure}{.5\textwidth}
    \centering
    \input{plots/color.knightGraph6by4to8.t.in.out.csv.lines.pgf}
    \caption{Overall running times}
  \end{subfigure}%
  \begin{subfigure}{.5\textwidth}
    \centering
    \input{plots/color.knightGraph6by4to8.t.in.out.csv.detailed.pgf}
    \caption{Percentage of time taken be each part}
  \end{subfigure}
  \caption{Knight graphs}
\end{figure}

\begin{figure}
  \begin{subfigure}{.5\textwidth}
    \centering
    \input{plots/color.hypercube20to40.t.in.out.csv.lines.pgf}
    \caption{Overall running times}
  \end{subfigure}%
  \begin{subfigure}{.5\textwidth}
    \centering
    \input{plots/color.hypercube20to40.t.in.out.csv.detailed.pgf}
    \caption{Percentage of time taken be each part}
  \end{subfigure}
  \caption{Hypercube graphs}
\end{figure}

\begin{figure}
  \TODO{TODOa}
  % \begin{subfigure}{.5\textwidth}
  %   \centering
  %   \input{plots/color.perf2.t.in.out.csv.lines.pgf}
  %   \caption{Overall running times}
  %   \label{plot:colorPerfLines}
  % \end{subfigure}%
  % \begin{subfigure}{.5\textwidth}
  %   \centering
  %   \input{plots/color.perf2.t.in.out.csv.detailed.pgf}
  %   \caption{Percentage of time taken be each part}
  %   \label{plot:colorPerfDet}
  % \end{subfigure}
  \caption{Split graphs}
\end{figure}

A few things of note. We notice that in rook graphs the graph manipulation other than calculating CSDP takes close to half of overall running time (\cref{plot:colorRookDet}). We didn't particularly optimize this, other than by use of methods developed for Berge graph recognition algorithm. There are surely some optimizations to be made here if need be. Altough, as we can see on other plots, it won't help im majority of the cases.


\subsection{Combinatorial Method}

Cite the paper.\\

On its complexity - point to appendix for pseudo-code.