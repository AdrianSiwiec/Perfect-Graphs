\section{Experiments}
\label{sec:experiments}

\subsubsection{Data sets}

Let us describe experiments and their results. All of our algorithms search for an odd hole or an odd antihole and stop when find one, or a evidence of one. Therefore, their running times are greatest with perfect graphs on the input and we decided to use mainly\todo{run some smart nonperfect tests} perfect graphs for our performance benchmarks. For every test, the vertex number were shuffled. For every randomly generated graph class and for each size, we ran the tests on 10 graphs generated with different seeds and took their average running time.

Below, we first present our data sets then overall time results on them and lastly a plot breaking down what parts of CCLSV and GPU CCLSV constitute their overall running time.

We ran tests on nine classes of perfect graphs.
\begin{itemize}
  \item perfect Erd\H{o}s--Rényi graphs,
  \item Random bipartite graphs,
  \item Line graphs of random bipartite graphs,
  \item Lattice graphs (\cref{fig:lattice}),
  \item Rook graphs (\cref{fig:rook}),
  \item Knight graphs (\cref{fig:knight}),
  \item Hypercube graphs (\cref{fig:hypercube}),
  \item Split graphs (\cref{fig:split}),
  \item Full binary trees.
\end{itemize}

\begin{figure}
  \input{tikzpictures/graphs.tex}
  \caption{Graph classes}
  \label{fig:graphClasses}
\end{figure}

In \Cref{fig:graphClasses} we present small examples of some of the above classes. Let us describe them briefly.

% An \emph{Erd\H{o}s--Rényi} model is a method of generating random graphs. Every possible edge is included in a graph with probability $1/2$. We generated them as long as we found enough perfect graphs for each $|V|$ we wanted to test. \todo{implement generating perfect graphs by removing long cycles} This method of generating perfect graphs is very inefficient and we couldn't generate any graphs with $|V| \geq 20$. Second, those graphs favour the na\"ive algortihm, because there is very low probability of long paths to appear.

We generate random bipartite graphs by creating two equal-sized sets of vertices and every possible edge between them has a probability of $1/2$ to appear. We also generate line graphs of bipartite graphs. This gives us graphs of varying $|V|$, so we repeated the process until we had sufficieng number of graphs for each $|V|$.

There are also a few interesting classes of perfect graphs that appear on a grid, or a checker board. In lattice graph, each vertex is connected to vertices that are above, below, to the left and to the right of it, if such vertices exist. See \Cref{fig:lattice} for an example of a $4 \times 4$ lattice graph. If we imagine our grid to be a chessboard we can define a rook graph to have an edge, when the rook from chess can move from one vertex to another in one move. See \Cref{fig:rook} for an example of $4 \times 4$ rook graph. In similar manner we can define a knight graph (\Cref{fig:knight}).

A hypercube is a generalization of a cube to a higher dimensional space. We use hypercubes that are not complete, to achieve higher granularity of data. In a hypercube of $n$ vertices there is an edge between vertices $u$ and $v$ if and only if binary representations of $u$ and $v$ differ by exactly one bit.

Split graphs we use are unions of cliques and independent sets of same size, with some edges between them. In generating them, each edge between a vertex from a clique and a vertex from an independent set has had $1/2$ chance to appear.

Finally, we benchmark on full binary trees to see how CCLSV works with a tree as an input.

\subsubsection{Time results}

% \begin{figure}
%   \centering
%   \input{plots/perf.t.in.out.csv.lines.pgf}
%   \caption{Random perfect graphs}
%   \label{plot:perfLines}
% \end{figure}

\begin{figure}
  \centering
  \input{plots/biparite.t.in.out.csv.lines.pgf}
  \caption{Random bipartite graphs}
  \label{plot:perf2Lines}
\end{figure}

\begin{figure}
  \centering
  \input{plots/perf2.t.in.out.csv.lines.pgf}
  \caption{Line graphs of random bipartite graphs}
  \label{plot:perf2Lines}
\end{figure}

\begin{figure}
  \centering
  \input{plots/grid6by5to11.t.in.out.csv.lines.pgf}
  \caption{Lattice graphs}
  \label{plot:gridLines}
\end{figure}

\begin{figure}
  \centering
  \input{plots/rookGraph5by4to7.t.in.out.csv.lines.pgf}
  \caption{Rook graphs}
  \label{plot:rookLines}
\end{figure}

\begin{figure}
  \centering
  \input{plots/knightGraph8by4to8.t.in.out.csv.lines.pgf}
  \caption{Knight graphs}
  \label{plot:knightLines}
\end{figure}

\begin{figure}
  \centering
  \input{plots/hypercubes20to55.t.in.out.csv.lines.pgf}
  \caption{Hypercube graphs}
  \label{plot:hypercubeLines}
\end{figure}

\begin{figure}
  \centering
  \input{plots/split20to50.t.in.out.csv.lines.pgf}
  \caption{Split graphs}
  \label{plot:splitLines}
\end{figure}

\begin{figure}
  \centering
  \input{plots/fullBinary20to100.t.in.out.csv.lines.pgf}
  \caption{Full binary trees}
  \label{plot:splitLines}
\end{figure}

\begin{figure}
  \centering
  \input{plots/detailed.csv.detailed.pgf}
  \caption{Detailed running times}
  \label{plot:perfDetailed}
\end{figure}

First, let us take a look at the performance of CCLSV algorithm. If we limit runtime to about two minutes, we can run it on graphs of sizes up to 40-70, depending on the type of the graph we test. What is interesting, that there isn't that much of a variance of the running time depending on the type of graph we test on. This is a big advantage of CCLSV over the na\"ive algorithm, which is highly dependent on the type of input. On some graphs, it works almost instantenously, what is to be expected, given its nature of enumerating paths. But on some graphs, e.g. lattice graphs (\Cref{plot:gridLines}) its overall running time grows much faster than CCLSV's.

Let us turn our attention to the GPU CCLSV's results. \Cref{plot:perfDetailed} shows breakdown of each implementation running times on a single graph of each class. We can clearly see that in most cases, testing possible near-cleaners takes most of the running time, so the speedup by the GPU is significant. 

Examples of full binary graph, and lattice graph show that getting near cleaners still can be a big bottleneck. Parallelization of this method could be considered in the future. A possible idea would be to use recently developed dynamic dictionary for the GPU \cite{Ashkiani2018}. When running GPU CCLSV on split graphs, quite a lot of time is spent checking simple structures. This should be easily parallelizable if need be, or if graphs that require it are encountered.

% When looking at the results (\Cref{plot:perfLines}), while na\"ive algorithm's time is almost zero, we see the CCLSV running time climbing with the growth of $|V|$, with only moderate improvement by GPU CCLSV. Slight GPU improvement is explained by anylysis of the components of the overall time (\Cref{plot:perfDet}). Testing all near cleaners takes up around half of total time, so we cannot speed up the overall time by much. These are also relatively small tests, so the latency from copying data to the GPU is significant.


% Next, we generated a random bipartite graphs (see paragraph above) and then calculated their line graphs. This gives us graphs of varying $|V|$, so we repeated the process until we had sufficieng number of graphs for each $|V|$. On \cref{plot:perf2Lines} we can see na\"ive algorithm being much faster on the majority of the tests, although its faster growth allows GPU CCLSV to be faster on the biggest tests.

% We turn our attention to graphs generated on a grid, or a checker board (see later paragraphs). First, we take lattice graphs. In lattice graph, each vertex is connected to vertices that are above, below, to the left and to the right of it, if such vertices exist. See \cref{fig:lattice} for an example of a $4 \times 4$ lattice graph.

% Let us take a look at \cref{plot:gridLines}. It is a clear example of why polynomial algorithms can be useful, even the ones with time complexity as high as CCLSV. For $|V| = 48$ the running time for the CCLSV is 22.2s, for GPU CCLSV is 7.7s and for na\"ive is 1.5s. Na\"ive is almost 15x faster. But with growing $|V|$ its running time grows very fast, reaching 41s for $|V| = 60$ and 210s for $|V| = 66$. CCLSV growth is much gentler and for $|V| = 66$ it is 2.5x faster than na\"ive.

% If we imagine our grid to be a chessboard we can define a rook graph to have an edge, when the rook from chess can move from one vertex to another in one move. See \cref{fig:rook} for an example of $4 \times 4$ Rook graph.

% Rook graphs have many more chords than Lattice graphs, so the na\"ive's performance is much better here. What is more interesting, the overall performance of CCLSV is much worse (\cref{plot:rookLines}). Looking at \cref{plot:rookDet} we can see that the majority of CCLSV time is spent checking all near cleaners. This can be explained by the fact that rook graphs are much denser than lattice graphs and have many more 3-vertex paths (see line TODO of \cref{alg:testNearCleaner}). This is confirmed by greater CCLSV GPU speedup of around 6x on graphs with $|V| = 35$.


% A hypercube is a generalization of a cube to a higher dimensional space. We use hypercubes that are not complete, to achieve higher granularity of data. In a hypercube of $n$ vertices there is an edge between vertices $u$ and $v$ if and only if binary representations of $u$ and $v$ differ by exactly one bit.

% Hypercube graphs tell a similar story to lattice graphs and knight graphs. Na\"ive algorithm is very fast at first, but becomes unbearably slow for $|V|$ higher than 55. Unfortunately, CCLSV doesn't fare much better, although it grows slower. Again, the speedup of GPU CCLSV is noticeable, being around 4.8x for $|V| = 55$.

% Split graphs we use are unions of cliques and independent sets of same size, with some edges between them. In generating them, each edge between a vertex from a clique and a vertex from an independent set has had $1/2$ chance to appear.

% There are no long paths here, so na\"ive algorithm works great (\cref{plot:splitLines}). What is interesting, when looking at detailed times of GPU CCLSV, we can see that checking the existence of simple forbidden structures takes more than 30\% of the time. This opens a possibility of further GPU speedups, not explored by us.

\section{Coloring Berge Graphs}

\subsection{Ellipsoid method}

We used an open source CSDP \cite{csdpRepo, csdp1999} library, that implements predictor corrector variant of the semidefinite programming algorithm to calculate $\vartheta(G)$, given $G$ on the input. The CSDP library has been used in many recent publications across different fields, such as \cite{Ampountolas_2017, Adasme_2011}.

Calculating $\vartheta(G)$ is the most complicated part of the coloring algorithm. With that done by an external library, the rest of the program is a straightforward implementation of the algorithms in \Cref{sec:coloringEllipsoid}. In most of our tests, the majority of running time was consumed on calculating $\vartheta$ of various graphs. As it was done by an external library, there isn't much optimization potential for us. One thing of note is, that specifying the precision of $\vartheta$ we want to calculate to be $1/3$ sped up the algorithm by TODO. Also, we cache results of calculatin $\vartheta$, meaning that throught whole execution of our coloring algorithm, we only calculate $\vartheta$ for each graph once. Our main goal of the implementation was to check if this method is still impractical, even on modern equipment. Let us proceed straight to experiments and results.

\subsubsection{Experiments and results}

We ran our tests on the data sets generated in the same way as for perfect graph recognition. We only adjusted grah sizes to get the running times of up to a couple of minutes. 

First, we present overall running times of the coloring algorithm (\Cref{fig:CSDPLines}) and then breakdown the running time in two parts: calculating $\vartheta$ by the CSDP library and graphs manipulations which constitute the rest of the coloring algorithm (\Cref{fig:CSDPDet}). We note that $\vartheta$ calculation is highly dependent on the type of the graph. For our biggest tested cases of $|V| = 48$, all required calculations of $\vartheta$ take almost 7 minutes in biparite graphs, but only 12 seconds in line graphs of bipartite graphs. Because CSDP library is highly optimized, it is expected that it would run much faster on some graphs. Hovewer, it is not clear what could we do to speedup the running times on tests that CSDP is slow on, such as bipartite graphs of lattice graphs. A potential improvement would be to again use CUDA, this time for $\vartheta$ calculations, possibly utilizing the cuSOLVER library \cite{cusolver}.

We notice that on some graphs, namely line graphs of bipartite graphs, rook graphs and split graphs the time taken by operations other than calculating $\vartheta$ by the CSDP library is quite significant. Hovewer, the overall running times on these graphs are low, so we didn't particularly optimize this, so probably some improvements could be made if need be.

\begin{figure}
  % \begin{subfigure}{.5\textwidth}
  %   \centering
  %   \input{plots/color.perf.t.in.out.csv.lines.pgf}
  %   \caption{Random perfect graphs}
  % \end{subfigure}%
  \begin{subfigure}{.5\textwidth}
    \centering
    \input{plots/color.biparite18to48.t.in.out.csv.lines.pgf}
    \caption{Random bipartite graphs}
  \end{subfigure}%
  \begin{subfigure}{.5\textwidth}
    \centering
    \input{plots/color.perfLin.t.in.out.csv.lines.pgf}
    \caption{Line graphs of random bipartite graphs}
  \end{subfigure}
  \begin{subfigure}{.5\textwidth}
    \centering
    \input{plots/color.lattice.t.in.out.csv.lines.pgf}
    \caption{Lattice graphs}
  \end{subfigure}%
  \begin{subfigure}{.5\textwidth}
    \centering
    \input{plots/color.rook.t.in.out.csv.lines.pgf}
    \caption{Rook graphs}
  \end{subfigure}
  \begin{subfigure}{.5\textwidth}
    \centering
    \input{plots/color.knight.t.in.out.csv.lines.pgf}
    \caption{Knight graphs}
  \end{subfigure}%
  \begin{subfigure}{.5\textwidth}
    \centering%
    \input{plots/color.hypercube.t.in.out.csv.lines.pgf}
    \caption{Hypercube graphs}
  \end{subfigure}
  \begin{subfigure}{.5\textwidth}
    \centering
    \input{plots/color.split.t.in.out.csv.lines.pgf}
    \caption{Split graphs}
  \end{subfigure}%
  \begin{subfigure}{.5\textwidth}
    \centering
    \input{plots/color.fullBinary.t.in.out.csv.lines.pgf}
    \caption{Full binary trees}
  \end{subfigure}
  \caption{Overall times of CSDP Color}
  \label{fig:CSDPLines}
\end{figure}

\begin{figure}
  \centering
  \input{plots/color.detailed.csv.detailed.pgf}
  \caption{Detailed times of coloring}
  \label{fig:CSDPDet}
\end{figure}
